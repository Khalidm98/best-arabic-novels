{
 "metadata": {
  "kernelspec": {
   "name": "python",
   "display_name": "Pyolite",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Python Technologist Application Test"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[This is](https://ar.wikipedia.org/wiki/%D9%82%D8%A7%D8%A6%D9%85%D8%A9_%D8%A3%D9%81%D8%B6%D9%84_%D9%85%D8%A6%D8%A9_%D8%B1%D9%88%D8%A7%D9%8A%D8%A9_%D8%B9%D8%B1%D8%A8%D9%8A%D8%A9) a Wikipedia webpage listing the 100 best Arabic novels according to the Arab Writers Union. In case it did not open for any reason try [this](https://www.marefa.org/%D9%82%D8%A7%D8%A6%D9%85%D8%A9_%D8%A3%D9%81%D8%B6%D9%84_%D8%A7%D9%84%D9%83%D8%AA%D8%A8_%D8%A7%D9%84%D8%B9%D8%B1%D8%A8%D9%8A%D8%A9) alternative link for the same info \n",
    "\n",
    "Using Python, do the following:\n",
    "\n",
    "1. Scrap the webapge to get the books table and write it to excel file, Keeping all the content from the HTML table including Hyper-links if any.\n",
    "2. Write the content to a Google sheet \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write your code in the following cell. You are free to add cells as much as you need."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Google Sheet integration requirements\n",
    "# Create Google Cloud Console project\n",
    "# Enable Google Drive API and Google Sheet API\n",
    "# Add service account and copy json key to project\n",
    "# https://docs.google.com/spreadsheets/d/1xdzsn2JpKTsjQMJLbskw8KKzhustJw2GAEU2Fs19CO0/edit?usp=sharing\n",
    "\n",
    "# PDF with arabic characters requirements\n",
    "# mkdir covers\n",
    "# copy \"Vazirmatn-Regular.ttf\" to \"site-packages/reportlab/fonts\""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "from bidi.algorithm import get_display\n",
    "from bs4 import BeautifulSoup\n",
    "from flask import Flask, abort, jsonify, render_template, request, send_from_directory\n",
    "from flask.views import MethodView\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font\n",
    "import pandas as pd\n",
    "import pygsheets\n",
    "from reportlab.graphics import renderPDF\n",
    "from reportlab.graphics.barcode.qr import QrCodeWidget\n",
    "from reportlab.graphics.shapes import Drawing\n",
    "from reportlab.lib.pagesizes import LETTER\n",
    "from reportlab.pdfbase.pdfmetrics import registerFont, stringWidth\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.pdfgen.canvas import Canvas\n",
    "import requests\n",
    "from rtl.reshaper import reshape"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def scrap_to_local_sheet():\n",
    "    base_url = 'https://ar.wikipedia.org'\n",
    "    url = 'https://ar.wikipedia.org/wiki/قائمة_أفضل_مئة_رواية_عربية'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Something went wrong!\")\n",
    "    pretty = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = pretty.find(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "    wb = Workbook()\n",
    "    sheet = wb.active\n",
    "    bold = Font(bold=True)\n",
    "    for col, label in enumerate(table.find_all(\"th\"), 1):\n",
    "        sheet.cell(1, col, label.text.strip()).font = bold\n",
    "\n",
    "    for row, row_tag in enumerate((table.find_all(\"tr\"))[1:], 2):\n",
    "        for col, cell_tag in enumerate(row_tag.find_all(\"td\"), 1):\n",
    "            cell = sheet.cell(row, col, cell_tag.text.strip())\n",
    "            a = cell_tag.find(\"a\")\n",
    "            if a:\n",
    "                cell.style = \"Hyperlink\"\n",
    "                cell.hyperlink = f\"{base_url}{a.attrs['href']}\"\n",
    "    wb.save(\"best_arabic_novels.xlsx\")\n",
    "\n",
    "scrap_to_local_sheet()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def scrap_to_google_sheet():\n",
    "    url = 'https://ar.wikipedia.org/wiki/قائمة_أفضل_مئة_رواية_عربية'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Something went wrong!\")\n",
    "    pretty = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = pretty.find(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "    df = pd.DataFrame(columns=[label.text.strip() for label in table.find_all(\"th\")])\n",
    "    for row_tag in table.find_all(\"tr\")[1:]:\n",
    "        df.loc[len(df)] = [cell.text.strip() for cell in row_tag.find_all(\"td\")]\n",
    "\n",
    "    google_client = pygsheets.authorize(service_file=\"sheets-service-account.json\")\n",
    "    google_sheet = google_client.open(\"best_arabic_novels\")[0]\n",
    "    google_sheet.set_dataframe(df, (1, 1))\n",
    "    google_sheet.add_conditional_formatting(\n",
    "        \"A1\", \"D1\", \"NOT_BLANK\", {\"textFormat\": {\"bold\": True}}\n",
    "    )\n",
    "\n",
    "scrap_to_google_sheet()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2 \n",
    "\n",
    "Create REST APIs in Python using Flask to read (Get) and write (Post, Delete, Put) the local excel file from the previous problem. Please make sure to bundle all the API dependencies to be uasble. Deploying the API to Heroku would be a big plus."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write your code in the following cell. You are free to add cells as much as you need."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "class FileAPI(MethodView):\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "    file_name = \"best_arabic_novels.xlsx\"\n",
    "\n",
    "    def get(self):\n",
    "        return send_from_directory(self.base_dir, self.file_name)\n",
    "\n",
    "    def post(self):\n",
    "        if not request.files:\n",
    "            response = jsonify({'details': 'Request is missing files!'})\n",
    "            response.status_code = 400\n",
    "            return response\n",
    "\n",
    "        file = request.files.get('file')\n",
    "        if not file:\n",
    "            response = jsonify({'file': 'This field is required!'})\n",
    "            response.status_code = 400\n",
    "            return response\n",
    "\n",
    "        if file.mimetype != \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "            response = jsonify({'details': 'Only \"xlsx\" files are allowed!'})\n",
    "            response.status_code = 400\n",
    "            return response\n",
    "\n",
    "        file.save(os.path.join(self.base_dir, self.file_name))\n",
    "        response = jsonify({'details': 'Created successfully.'})\n",
    "        response.status_code = 201\n",
    "        return response\n",
    "\n",
    "    def put(self):\n",
    "        file = request.files.get('file')\n",
    "        if not file:\n",
    "            response = jsonify({'details': 'Updated successfully.'})\n",
    "            return response\n",
    "\n",
    "        if file.mimetype != \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "            response = jsonify({'details': 'Only \"xlsx\" files are allowed!'})\n",
    "            response.status_code = 400\n",
    "            return response\n",
    "\n",
    "        file.save(os.path.join(self.base_dir, self.file_name))\n",
    "        response = jsonify({'details': 'Updated successfully.'})\n",
    "        response.status_code = 201\n",
    "        return response\n",
    "\n",
    "    def delete(self):\n",
    "        path = os.path.join(self.base_dir, self.file_name)\n",
    "        if not os.path.exists(path):\n",
    "            abort(404)\n",
    "        os.remove(path)\n",
    "        response = jsonify({\"details\": \"Deleted successfully.\"})\n",
    "        response.status_code = 204\n",
    "        return response\n",
    "\n",
    "\n",
    "app.add_url_rule(\n",
    "    \"/file/\",\n",
    "    view_func=FileAPI.as_view('file_api'),\n",
    "    methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\"],\n",
    ")\n",
    "\n",
    "app.run()"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3\n",
    "\n",
    "Write a tool to create a PDF cover for the books, following the attached example \"book-cover-sample.pdf\". Considering the following:\n",
    "\n",
    "    1. The QR code should embed the book hyperlink from Wikipedia.\n",
    "    2. The QR code should be clickable to let the users acess it by clicking on it.\n",
    "    3. Include all the covers in one directory and compress it in ZIP format.\n",
    "    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write your code in the following cell. You are free to add cells as much as you need."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def export_novels_covers():\n",
    "    base_url = 'https://ar.wikipedia.org'\n",
    "    url = 'https://ar.wikipedia.org/wiki/قائمة_أفضل_مئة_رواية_عربية'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Something went wrong!\")\n",
    "    pretty = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = pretty.find(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "    registerFont(TTFont(\"Vazirmatn\", \"Vazirmatn-Regular.ttf\"))\n",
    "    for row, row_tag in enumerate((table.find_all(\"tr\"))[1:], 2):\n",
    "        cells = row_tag.find_all(\"td\")\n",
    "        rank = cells[0].text.strip()\n",
    "        novel = cells[1].text.strip()\n",
    "        author = cells[2].text.strip()\n",
    "        novel_url = f'{base_url}{cells[1].a.attrs[\"href\"]}'\n",
    "\n",
    "        pdf = Canvas(\n",
    "            f\"covers/{rank.zfill(3)}. {novel}.pdf\",\n",
    "            initialFontName=\"Vazirmatn\",\n",
    "            initialFontSize=32,\n",
    "            pagesize=LETTER,\n",
    "        )\n",
    "\n",
    "        qr = QrCodeWidget(novel_url, barHeight=324, barWidth=324, barBorder=0)\n",
    "        d = Drawing()\n",
    "        d.add(qr)\n",
    "        renderPDF.draw(d, pdf, 144, 288)\n",
    "        pdf.linkURL(novel_url, (144, 288, 468, 612))\n",
    "\n",
    "        novel_ar = get_display(reshape(novel))\n",
    "        author_ar = get_display(reshape(author))\n",
    "        pdf.drawString((LETTER[0] - stringWidth(novel_ar, \"Vazirmatn\", 32)) / 2, 216, novel_ar)\n",
    "        pdf.drawString((LETTER[0] - stringWidth(author_ar, \"Vazirmatn\", 32)) / 2, 144, author_ar)\n",
    "        pdf.save()\n",
    "        \n",
    "export_novels_covers()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}